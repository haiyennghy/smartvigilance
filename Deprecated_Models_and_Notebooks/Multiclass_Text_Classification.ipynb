{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multiclass Text Classification",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8fb16714ce924f619b83d6251a2da4ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_31ded14aeb5e4f5096617fc7091abf5a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8413db3d512c4c0cb9fba5bf3d39cc69",
              "IPY_MODEL_94a72a89cc8d49feb7681b849218fdd9"
            ]
          }
        },
        "31ded14aeb5e4f5096617fc7091abf5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8413db3d512c4c0cb9fba5bf3d39cc69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3b3427e7afed4099bab1c01998677b42",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2daf90fe251a4af98ebdf62651fa374a"
          }
        },
        "94a72a89cc8d49feb7681b849218fdd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4a2143990d84422093fe1c340724c615",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 800kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8a4ccda877d8494082a3ea4602af537c"
          }
        },
        "3b3427e7afed4099bab1c01998677b42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2daf90fe251a4af98ebdf62651fa374a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4a2143990d84422093fe1c340724c615": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8a4ccda877d8494082a3ea4602af537c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "19c423f2ab25495e9c9de9e4b74ce167": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_dc03e40a0fbd44299e132ca934fda4a3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2247e4e866544d9396aa34a3529ff746",
              "IPY_MODEL_f074c49d26094a8c91ff5de2813f3495"
            ]
          }
        },
        "dc03e40a0fbd44299e132ca934fda4a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2247e4e866544d9396aa34a3529ff746": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_aaa968a30e584c4f85be4c4721bde3a5",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6cb3e957afb94cd7be3337cebf0d60fa"
          }
        },
        "f074c49d26094a8c91ff5de2813f3495": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c1190d5fbea84bffa426c1cf1635189f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 1.40kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6aab1aeb09e1445d93767b2c01d7393d"
          }
        },
        "aaa968a30e584c4f85be4c4721bde3a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6cb3e957afb94cd7be3337cebf0d60fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c1190d5fbea84bffa426c1cf1635189f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6aab1aeb09e1445d93767b2c01d7393d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "69f1a2e526fb4adeb87ea5a31c7e8597": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_273bb7b0c15b4f93a98bc932edc2b94f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a2d33f0a9b7f4cbcaa42b0bd42dba38c",
              "IPY_MODEL_726d55c74bde443faa429d8d00807b2d"
            ]
          }
        },
        "273bb7b0c15b4f93a98bc932edc2b94f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a2d33f0a9b7f4cbcaa42b0bd42dba38c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_189d07f67d144c7c94f8ebc00529ddf3",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9775a9b26a6846ec957b8549b8cb35bb"
          }
        },
        "726d55c74bde443faa429d8d00807b2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0b4ca75c3324450382f614d8724d88d8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:24&lt;00:00, 18.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_40c33a299bb04c9fac1e937a8b89c622"
          }
        },
        "189d07f67d144c7c94f8ebc00529ddf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9775a9b26a6846ec957b8549b8cb35bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0b4ca75c3324450382f614d8724d88d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "40c33a299bb04c9fac1e937a8b89c622": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Be4d5jFm8Fwk"
      },
      "source": [
        "# **Used 15, 000 reports from the pickle file to train and test the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0bp3OLYlY-w"
      },
      "source": [
        "!pip install stanza\n",
        "!pip install tqdm\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bb79-djxYKnQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc2b7868-b275-43ea-916b-1d9a09906d3e"
      },
      "source": [
        "# Test if CUDA is available\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Nov 30 07:41:44 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.38       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   65C    P8    11W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyTcs3YG2C7d"
      },
      "source": [
        "# Linear algebra and array datastructures\n",
        "import numpy as np\n",
        "\n",
        "# For easy handling of dataset\n",
        "import pandas as pd\n",
        "\n",
        "# For Accuracy and F1 metrics\n",
        "from sklearn import metrics\n",
        "\n",
        "# Visualizations\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# PyTorch dependencies\n",
        "import torch\n",
        "import transformers\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertTokenizer, BertModel, BertConfig\n",
        "\n",
        "# Supress unnecessary warnings from Transformers and Matplotlib\n",
        "import re\n",
        "import warnings\n",
        "import logging"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsiIQABWWZck"
      },
      "source": [
        "def warn(*args, **kwargs):\n",
        "  pass\n",
        "\n",
        "def set_global_logging_level(level=logging.ERROR, prefices=[\"\"]):\n",
        "    prefix_re = re.compile(fr'^(?:{ \"|\".join(prefices) })')\n",
        "    for name in logging.root.manager.loggerDict:\n",
        "      if re.match(prefix_re, name):\n",
        "        logging.getLogger(name).setLevel(level)\n",
        "\n",
        "warnings.warn = warn\n",
        "set_global_logging_level(logging.ERROR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pih6bN5D4gtf"
      },
      "source": [
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "-PQQ90k00x8m",
        "outputId": "996f205f-0785-41ae-cc8b-4c01ef3ed90c"
      },
      "source": [
        "# Convert the labels into One Hot Encoding Vectors\n",
        "\n",
        "df = pd.read_csv('/content/product_dataset_50k.csv')\n",
        "\n",
        "# One hot encoder\n",
        "one_hot = pd.get_dummies(df[\"Label\"])\n",
        "\n",
        "#print(len(df), len(one_hot))\n",
        "\n",
        "df = df.drop('Label',axis = 1)\n",
        "# Join the encoded df\n",
        "\n",
        "df = df.join(one_hot)\n",
        "df.to_csv(\"./product_dataset_onehot.csv\", sep=',', index=True)\n",
        "\n",
        "del(one_hot)\n",
        "\n",
        "df['list'] = df[df.columns[1:]].values.tolist()   # Don't foget to set the index to 1 when running on 50k datset (not req anymore)\n",
        "new_df = df[['Text', 'list']].copy()\n",
        "\n",
        "#print(len(new_df))\n",
        "\n",
        "new_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>currently unknown whether device may cause con...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>clinician report day implant place fdi 26 fail...</td>\n",
              "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>insulin pump button response due flattened dom...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>currently unknown whether device may cause con...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>implant fayl due loss osseointegrate</td>\n",
              "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text                                     list\n",
              "0  currently unknown whether device may cause con...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
              "1  clinician report day implant place fdi 26 fail...  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
              "2  insulin pump button response due flattened dom...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
              "3  currently unknown whether device may cause con...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
              "4               implant fayl due loss osseointegrate  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yj5N7PSQgPKA"
      },
      "source": [
        "def learning_plots(train_loss, validation_loss):\n",
        "    plt.style.use('seaborn')\n",
        "    plt.suptitle('Loss Curves', fontsize=35)\n",
        "    plt.plot(train_loss, label='Training Loss')\n",
        "    plt.plot(validation_loss, color='orange', label='Validation Loss')\n",
        "    plt.legend()\n",
        "    #plt.legend(['Training Loss'])\n",
        "    plt.xlabel('Steps/Batches')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.show()\n",
        "  \n",
        "def print_confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14):\n",
        "    df_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names)\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "\n",
        "    heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\", cbar = True)\n",
        "\n",
        "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
        "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
        "    plt.ylabel('True Labels')\n",
        "    plt.xlabel('Predicted Labels')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHSUQKRu5UmB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "8fb16714ce924f619b83d6251a2da4ae",
            "31ded14aeb5e4f5096617fc7091abf5a",
            "8413db3d512c4c0cb9fba5bf3d39cc69",
            "94a72a89cc8d49feb7681b849218fdd9",
            "3b3427e7afed4099bab1c01998677b42",
            "2daf90fe251a4af98ebdf62651fa374a",
            "4a2143990d84422093fe1c340724c615",
            "8a4ccda877d8494082a3ea4602af537c"
          ]
        },
        "outputId": "61ac7fe5-a1a1-4df0-b516-53ff53bb091b"
      },
      "source": [
        "# Sections of config\n",
        "\n",
        "# Defining some key variables that will be used later on in the training\n",
        "MAX_LEN = 300   # Very crucial parameter. But, due to limited GPU mememory can't push this value further upto 512!!!!!\n",
        "TRAIN_BATCH_SIZE = 32\n",
        "VALID_BATCH_SIZE = 24  # Default can be set to 8 (safe with basic GPU and low RAM)\n",
        "EPOCHS = 1\n",
        "LEARNING_RATE = 1e-05\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8fb16714ce924f619b83d6251a2da4ae",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfnLymfw5ddo"
      },
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.comment_text = dataframe.Text\n",
        "        self.targets = self.data.list\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.comment_text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        comment_text = str(self.comment_text[index])\n",
        "        comment_text = \" \".join(comment_text.split())\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            comment_text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            pad_to_max_length=True,\n",
        "            truncation = True,\n",
        "            return_token_type_ids=True\n",
        "        )\n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "        token_type_ids = inputs[\"token_type_ids\"]\n",
        "\n",
        "\n",
        "        return {\n",
        "            'ids': torch.tensor(ids, dtype=torch.long),\n",
        "            'mask': torch.tensor(mask, dtype=torch.long),\n",
        "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
        "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPQyCMMR5gQT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f9d0837-4243-4d58-b986-501677c35341"
      },
      "source": [
        "# Creating the dataset and dataloader for the neural network\n",
        "# Split ratios: Training (70%), Validation (15%), Testing (15%)\n",
        "\n",
        "train_size = 0.7\n",
        "\n",
        "train_dataset = new_df.sample(frac=train_size, random_state=200)\n",
        "\n",
        "validation_dataset = new_df.drop(train_dataset.index)\n",
        "\n",
        "# 50% of Validation dataset and not from the entire dataset\n",
        "test_dataset = validation_dataset.sample(frac=0.5, random_state=200)\n",
        "\n",
        "# Remove samples from validation dataset who are also seen in testset\n",
        "validation_dataset = validation_dataset.drop(test_dataset.index)\n",
        "\n",
        "# test_dataset=new_df.drop(train_dataset.index).reset_index(drop=True)\n",
        "\n",
        "train_dataset = train_dataset.reset_index(drop=True)\n",
        "test_dataset = test_dataset.reset_index(drop=True)\n",
        "validation_dataset = validation_dataset.reset_index(drop=True)\n",
        "\n",
        "print(f\"Unique samples in Trainset: {len(train_dataset)}, Testset: {len(test_dataset)} and Validationset: {len(validation_dataset)}\")\n",
        "\n",
        "training_set = CustomDataset(train_dataset, tokenizer, MAX_LEN)\n",
        "testing_set = CustomDataset(test_dataset, tokenizer, MAX_LEN)\n",
        "validation_set = CustomDataset(validation_dataset, tokenizer, MAX_LEN)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique samples in Trainset: 35000, Testset: 7500 and Validationset: 7500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iU3WoR36Jeo"
      },
      "source": [
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "validation_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)\n",
        "validation_loader = DataLoader(validation_set, **validation_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfYnB_e66Mqn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "19c423f2ab25495e9c9de9e4b74ce167",
            "dc03e40a0fbd44299e132ca934fda4a3",
            "2247e4e866544d9396aa34a3529ff746",
            "f074c49d26094a8c91ff5de2813f3495",
            "aaa968a30e584c4f85be4c4721bde3a5",
            "6cb3e957afb94cd7be3337cebf0d60fa",
            "c1190d5fbea84bffa426c1cf1635189f",
            "6aab1aeb09e1445d93767b2c01d7393d",
            "69f1a2e526fb4adeb87ea5a31c7e8597",
            "273bb7b0c15b4f93a98bc932edc2b94f",
            "a2d33f0a9b7f4cbcaa42b0bd42dba38c",
            "726d55c74bde443faa429d8d00807b2d",
            "189d07f67d144c7c94f8ebc00529ddf3",
            "9775a9b26a6846ec957b8549b8cb35bb",
            "0b4ca75c3324450382f614d8724d88d8",
            "40c33a299bb04c9fac1e937a8b89c622"
          ]
        },
        "outputId": "e51c27b8-f426-444d-d522-8c301f9efd37"
      },
      "source": [
        "# Creating the customized model, by adding a drop out and a dense layer on top of distil bert to get the final output for the model. \n",
        "\n",
        "class BERTClass(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BERTClass, self).__init__()\n",
        "        self.l1 = transformers.BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.l2 = torch.nn.Dropout(0.3)\n",
        "        self.l3 = torch.nn.Linear(768, 13) # 13 output classes for 50,000 documents\n",
        "    \n",
        "    def forward(self, ids, mask, token_type_ids):\n",
        "        _, output_1= self.l1(ids, attention_mask = mask, token_type_ids = token_type_ids)\n",
        "        output_2 = self.l2(output_1)\n",
        "        output = self.l3(output_2)\n",
        "        return output\n",
        "\n",
        "model = BERTClass()\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "19c423f2ab25495e9c9de9e4b74ce167",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "69f1a2e526fb4adeb87ea5a31c7e8597",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BERTClass(\n",
              "  (l1): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (l2): Dropout(p=0.3, inplace=False)\n",
              "  (l3): Linear(in_features=768, out_features=13, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiAL0O5A6Vvm"
      },
      "source": [
        "def loss_fn(outputs, targets):\n",
        "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MeAiqg-6W0o"
      },
      "source": [
        "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjGvbY3X22pC"
      },
      "source": [
        "def validation(epoch):\n",
        "    model.eval()\n",
        "    val_epoch_loss = []\n",
        "    #print(\"\\nValidating the model:\")\n",
        "    with torch.no_grad():\n",
        "      for _,data in enumerate(validation_loader, 0):\n",
        "          ids = data['ids'].to(device, dtype = torch.long)\n",
        "          mask = data['mask'].to(device, dtype = torch.long)\n",
        "          token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "          targets = data['targets'].to(device, dtype = torch.float)\n",
        "\n",
        "          outputs = model(ids, mask, token_type_ids)\n",
        "          #optimizer.zero_grad()\n",
        "\n",
        "          loss = loss_fn(outputs, targets)\n",
        "          #if _ % 100==0:\n",
        "              #print(f'Epoch: {epoch}, Step: {_}, Validation Loss:  {loss.item()}')\n",
        "\n",
        "          val_epoch_loss.append(loss.item())\n",
        "\n",
        "    # print(\"\\n-------------------------------------------------------------------\")\n",
        "    return val_epoch_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAsv6C6x6aI0"
      },
      "source": [
        "def train(epoch):\n",
        "    epoch_loss = []\n",
        "    validation_epoch_loss = []\n",
        "    #print(\"Training the model:\\n\")\n",
        "    for _,data in enumerate(training_loader, 0):\n",
        "        model.train()\n",
        "        ids = data['ids'].to(device, dtype = torch.long)\n",
        "        mask = data['mask'].to(device, dtype = torch.long)\n",
        "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "        targets = data['targets'].to(device, dtype = torch.float)\n",
        "\n",
        "        outputs = model(ids, mask, token_type_ids)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = loss_fn(outputs, targets)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Performing validation with each step/epoch of training\n",
        "        val_epoch_loss = validation(epoch)\n",
        "        validation_loss = sum(val_epoch_loss)/len(val_epoch_loss)\n",
        "\n",
        "        if _ % 200 == 0:\n",
        "            print(f'Epoch: {epoch}, Step: {_}, Training Loss:  {loss.item()}, Validation Loss:  {validation_loss}\\n')\n",
        "        \n",
        "\n",
        "        epoch_loss.append(loss.item())\n",
        "        validation_epoch_loss.append(validation_loss)\n",
        "\n",
        "    print(\"\\nTraining Complete!\")\n",
        "    return epoch_loss, validation_epoch_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0Etk3Pt6cS1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e48a9789-1b0e-4456-e18d-3496ac4b0753"
      },
      "source": [
        "#train_loss = []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    train_epoch_loss, validation_epoch_loss = train(epoch)\n",
        "    # train_loss.append(sum(epoch_loss)/len(epoch_loss)) -> Uncomment and use this variable to plot the final Training Loss curve when running for more than 1 epochs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Step: 0, Training Loss:  0.6909028887748718, Validation Loss:  0.6726009318242058\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6vpuhZTCue1"
      },
      "source": [
        "# Currently printing loss curve only for 1 epoch (which has close to 400 batches or steps) -> in our case 1 epoch is more than enough for training\n",
        "\n",
        "learning_plots(train_epoch_loss, validation_epoch_loss)\n",
        "#learning_plots(np.linspace(1, len(train_epoch_loss), len(train_epoch_loss)).astype(int), train_epoch_loss, val_epoch_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drIR3B6vXZBK"
      },
      "source": [
        "def testing(epoch):\n",
        "    model.eval()\n",
        "    fin_targets=[]\n",
        "    fin_outputs=[]\n",
        "    with torch.no_grad():\n",
        "        for _, data in enumerate(testing_loader, 0):\n",
        "            ids = data['ids'].to(device, dtype = torch.long)\n",
        "            mask = data['mask'].to(device, dtype = torch.long)\n",
        "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "            targets = data['targets'].to(device, dtype = torch.float)\n",
        "            outputs = model(ids, mask, token_type_ids)\n",
        "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "    return fin_outputs, fin_targets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljVbm5XLXbGk"
      },
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    outputs, targets = testing(epoch)\n",
        "    outputs = np.array(outputs) >= 0.3\n",
        "    accuracy = metrics.accuracy_score(targets, outputs)\n",
        "    f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n",
        "    f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n",
        "    f1_score_weighted = metrics.f1_score(targets, outputs, average='weighted')\n",
        "\n",
        "    print(f\"\\nOverall Accuracy = {accuracy}\")\n",
        "    print(f\"\\nOverall F1 Score (Micro) = {f1_score_micro}\")\n",
        "    print(f\"\\nOverall F1 Score (Macro) = {f1_score_macro}\")\n",
        "    print(f\"\\nOverall F1 Score (Weighted) = {f1_score_weighted}\")\n",
        "\n",
        "\n",
        "    labels_15k = [0,1,2,3,4,5,6,7,8]\n",
        "    label_names_15k = [\"CAW\", \"DXZ\", \"DZE\", \"FTM\", \"GAS\", \"HRY\", \"JAA\", \"MRD\", \"OYC\"]\n",
        "\n",
        "    labels_50k = [0,1,2,3,4,5,6,7,8,9,10,11,12]\n",
        "    label_names_50k = [\"BYG\", \"CAW\", \"CCN\", \"DXZ\", \"DZE\", \"FTM\", \"GAS\", \"HRY\", \"HWC\", \"JAA\", \"LWQ\", \"MRD\", \"OYC\"]\n",
        "\n",
        "    targets = np.asarray(targets)\n",
        "\n",
        "    confusion_mtx = metrics.confusion_matrix(targets.argmax(axis=1), outputs.argmax(axis=1), labels = labels_50k)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeeCMEiyrjpL"
      },
      "source": [
        "print(\"\\nOverall Classification Report:\")\n",
        "print(f\"\\n {metrics.classification_report(targets.argmax(axis=1), outputs.argmax(axis=1), labels = labels_50k, target_names = label_names_50k)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CvSO1kDrnAx"
      },
      "source": [
        "print_confusion_matrix(confusion_mtx, label_names_50k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COG1oQAau422"
      },
      "source": [
        "**Experiments** (Still debugging some issues with torch tensor shapes)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ofnLOBmsNSF"
      },
      "source": [
        "def get_item_tensor(sentence):\n",
        "  inputs = tokenizer.encode_plus(sentence, None, add_special_tokens=True, max_length=200, pad_to_max_length=True, return_token_type_ids=True)\n",
        "  ids = inputs['input_ids']\n",
        "  mask = inputs['attention_mask']\n",
        "  token_type_ids = inputs[\"token_type_ids\"]\n",
        "\n",
        "\n",
        "  return {\n",
        "            'ids': torch.tensor(ids, dtype=torch.long),\n",
        "            'mask': torch.tensor(mask, dtype=torch.long),\n",
        "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long)\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPPP0M3gpx0D"
      },
      "source": [
        "# Real-time inference to map \"event descriptions to correspnding product codes\"\n",
        "\n",
        "print(\"\\n1. Classify Sentence\")\n",
        "print(\"\\n2. Exit\")\n",
        "while True:\n",
        "  option = int(input(\"\\nPlease select any option: \"))\n",
        "  if option == 1:\n",
        "    sentence = input(\"\\nPlease enter a description which you want to classify: \")\n",
        "    tokenized_output = get_item_tensor(sentence)\n",
        "\n",
        "    #print(tokenized_output[\"ids\"].shape, tokenized_output[\"mask\"].shape, tokenized_output[\"token_type_ids\"].shape)\n",
        "\n",
        "    ids = tokenized_output[\"ids\"].to(device, dtype = torch.long)\n",
        "    mask = tokenized_output[\"mask\"].to(device, dtype = torch.long)\n",
        "    token_type_ids = tokenized_output[\"token_type_ids\"].to(device, dtype = torch.long)\n",
        "\n",
        "    output = model(ids.unsqueeze(0),mask.unsqueeze(0),token_type_ids)\n",
        "    print(\"\\n\")\n",
        "    print(output.tolist())\n",
        "  \n",
        "  else:\n",
        "    print(\"\\nBye\")\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0Js1uN_DvCe"
      },
      "source": [
        "----------------------------------------------------------------------------------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lr_ik9oBEXwt"
      },
      "source": [
        "# **Code to create Dataset (csv) with One-hot Embedded Labels**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtLsvHPflR4i"
      },
      "source": [
        "import string\n",
        "import stanza\n",
        "import pickle\n",
        "import nltk\n",
        "from tqdm import tqdm\n",
        "from pprint import pprint\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "#from spacy_stanza import StanzaLanguage\n",
        "#from spacy.attrs import ORTH, NORM\n",
        "\n",
        "\n",
        "class MaudePreprocessor():\n",
        "\n",
        "    def __init__(self):\n",
        "        stanza.download('en', package='craft', processors='tokenize,pos,lemma') #package='mimic'\n",
        "        self.nlp = stanza.Pipeline('en', package='craft', processors='tokenize,pos,lemma')\n",
        "        #snlp = stanza.Pipeline(lang='en', package='craft', processors='tokenize,pos,lemma')\n",
        "        #self.nlp = StanzaLanguage(snlp)\n",
        "        #self.nlp.tokenizer.add_special_case(\"(B)(4)\", [{ORTH: \"(B)(4)\"}])\n",
        "        #self.nlp.tokenizer.add_special_case(\"(B)(6)\", [{ORTH: \"(B)(6)\"}])\n",
        "\n",
        "\n",
        "    # doesn't store tokens, ssplit=True\n",
        "    def tokenizer_lemmatizer(self, text):\n",
        "        doc = self.nlp(text)\n",
        "        seg_text = []\n",
        "        for sent in doc.sentences:\n",
        "            sentence = [token.lemma.lower() for token in sent.words]\n",
        "            seg_text.append(sentence)\n",
        "        return seg_text\n",
        "\n",
        "        '''\n",
        "        #for spacy language objects\n",
        "        doc = self.nlp(text)\n",
        "        seg_text = []\n",
        "        # no sentence splitting (yet)\n",
        "        for sent in doc.sents:\n",
        "            sent = [word.lemma_ for word in sent]\n",
        "            #sent = [word for word in sent.words]\n",
        "            seg_text.append(sent)\n",
        "        return seg_text\n",
        "        '''\n",
        "\n",
        "\n",
        "    def clean(self, seg_text):\n",
        "        clean_text = []\n",
        "        for sent in seg_text:\n",
        "            clean_sent = []\n",
        "            for tok in sent:\n",
        "                # / should probably not be in punctuation, (B)(4) should be one token\n",
        "                if tok not in stopwords.words('english') and tok not in string.punctuation and len(tok)>1:\n",
        "                    clean_sent.append(tok)\n",
        "            clean_text.append(clean_sent)\n",
        "        return clean_text\n",
        "\n",
        "    def pipe(self, text, ssplit=False):\n",
        "        t = self.tokenizer_lemmatizer(text)\n",
        "        t = self.clean(t)\n",
        "        if not ssplit:\n",
        "            t = [token for sent in t for token in sent]\n",
        "        return t\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    path = '/content/drive/MyDrive/100000_random_entries_prod_codes (1).pkl'\n",
        "    P = MaudePreprocessor()\n",
        "    f = open(path, 'rb')\n",
        "    subset = pickle.load(f)\n",
        "    final_texts = []\n",
        "    label_list = []\n",
        "\n",
        "    # Don't forget to add TQDM when code is moved to .py instead of these bloody notebooks!!!\n",
        "    for key in (subset):\n",
        "        label = subset[key][\"device\"][0]['device_report_product_code']\n",
        "        if \"mdr_text\" in subset[key]:\n",
        "            per_device_texts = []\n",
        "            for entry in subset[key][\"mdr_text\"]:\n",
        "                text = entry['text']\n",
        "                processed_text = \" \".join(P.pipe(text))\n",
        "                per_device_texts.append(processed_text)\n",
        "\n",
        "        final_texts.append(\" \".join(per_device_texts))\n",
        "        label_list.append(label)\n",
        "\n",
        "        # When TQDM is used, remove this print block\n",
        "        if len(label_list) % 5000 == 0:\n",
        "          print(f\"Processed {len(label_list)} files so far\")\n",
        "\n",
        "        if len(label_list) >= 50000: \n",
        "          print(\"Complete!!!\")\n",
        "          break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJULbE5r5Zju"
      },
      "source": [
        "# Dataset csv file dumper\n",
        "\n",
        "df = pd.DataFrame(data={\"Text\": final_texts, \"Label\": label_list})\n",
        "df.to_csv(\"./product_dataset.csv\", sep=',', index=False)\n",
        "print(\"Dump complete!\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}